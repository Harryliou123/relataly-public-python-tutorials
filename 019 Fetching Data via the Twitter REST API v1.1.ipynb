{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json \n",
    "import tempfile\n",
    "import pathlib \n",
    "from datetime import datetime as dt\n",
    "from uuid import uuid4\n",
    "from requests_oauthlib import OAuth1Session\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "from os import path\n",
    "\n",
    "# imports the twitter_secrets python file in which we store the twitter API keys\n",
    "from twitter_secrets import twitter_secrets as ts\n",
    "\n",
    "\n",
    "\n",
    "# the write path in which the data will be stored. If it does not yet exist, it will be created\n",
    "out_path = \"/twitter/output/\"\n",
    "pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# establish the connection by providing the twitter API keys from the twitter file\n",
    "twitter = OAuth1Session(\n",
    "    client_key=ts.CONSUMER_KEY,\n",
    "    client_secret=ts.CONSUMER_SECRET,\n",
    "    resource_owner_key=ts.ACCESS_TOKEN,\n",
    "    resource_owner_secret=ts.ACCESS_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Retrieving Tweets by Searchtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stream.twitter.com/1.1/statuses/filter.json?track=2021&language=en&date_since=2019-12-01\n",
      "Retrieving max 10 Tweets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>username</th>\n",
       "      <th>userlocation</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1345400537156616194</td>\n",
       "      <td>classicwhiskey</td>\n",
       "      <td>Yavin IV</td>\n",
       "      <td>Sat Jan 02 16:04:19 +0000 2021</td>\n",
       "      <td>ask yoni\\n\\nIdk what that means, but okay XD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1345400537164857344</td>\n",
       "      <td>ChucklingBears</td>\n",
       "      <td>None</td>\n",
       "      <td>Sat Jan 02 16:04:19 +0000 2021</td>\n",
       "      <td>Finally! The word is out. So much has been hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1345400537320095745</td>\n",
       "      <td>Lastone020501</td>\n",
       "      <td>None</td>\n",
       "      <td>Sat Jan 02 16:04:19 +0000 2021</td>\n",
       "      <td>RT @Raze0013: ‚òÄÔ∏èüê∂#MusicBNK48 ‚ú®‚ú®\\nHappy New Yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1345400537248899072</td>\n",
       "      <td>dasGielchen</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Sat Jan 02 16:04:19 +0000 2021</td>\n",
       "      <td>RT @Lindatiny21: ATINY'S  VOTE FOR TODAY! Give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345400537311825923</td>\n",
       "      <td>sherijr</td>\n",
       "      <td>Baltimore MD Citizen 2012</td>\n",
       "      <td>Sat Jan 02 16:04:19 +0000 2021</td>\n",
       "      <td>RT @BoycottUtah: Fellow citizens of Georgia. Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1345400537345265665</td>\n",
       "      <td>kvetchup</td>\n",
       "      <td>London, UK to Los Angeles, CA</td>\n",
       "      <td>Sat Jan 02 16:04:19 +0000 2021</td>\n",
       "      <td>@qorquiq @nicholestrano Jacket over game pajam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1345400537328414720</td>\n",
       "      <td>fxyxwxe</td>\n",
       "      <td>üç∑‚Ä¢üßÄ‚Ä¢üçû‚Ä¢ü¶™‚Ä¢üçã‚Ä¢üßÇ‚Ä¢üçï‚Ä¢üçü‚Ä¢üç¶‚Ä¢ü•ù</td>\n",
       "      <td>Sat Jan 02 16:04:19 +0000 2021</td>\n",
       "      <td>RT @asdfghjunyeol: It's 2021, but my heart sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1345400537395691523</td>\n",
       "      <td>tarungarg87</td>\n",
       "      <td>None</td>\n",
       "      <td>Sat Jan 02 16:04:19 +0000 2021</td>\n",
       "      <td>RT @FaheemYounus: Should I continue my Twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1345400537626402816</td>\n",
       "      <td>BurauFred</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Sat Jan 02 16:04:19 +0000 2021</td>\n",
       "      <td>RT @RudyGiuliani: Sunday January 3, 2021, Dr. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1345400537584431104</td>\n",
       "      <td>TheBenduPodcast</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Sat Jan 02 16:04:19 +0000 2021</td>\n",
       "      <td>RT @sw_holocron: REVIEW: Star Wars The High Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                userid         username                   userlocation  \\\n",
       "0  1345400537156616194   classicwhiskey                       Yavin IV   \n",
       "1  1345400537164857344   ChucklingBears                           None   \n",
       "2  1345400537320095745    Lastone020501                           None   \n",
       "3  1345400537248899072      dasGielchen                        Germany   \n",
       "4  1345400537311825923          sherijr     Baltimore MD Citizen 2012    \n",
       "5  1345400537345265665         kvetchup  London, UK to Los Angeles, CA   \n",
       "6  1345400537328414720          fxyxwxe            üç∑‚Ä¢üßÄ‚Ä¢üçû‚Ä¢ü¶™‚Ä¢üçã‚Ä¢üßÇ‚Ä¢üçï‚Ä¢üçü‚Ä¢üç¶‚Ä¢ü•ù   \n",
       "7  1345400537395691523      tarungarg87                           None   \n",
       "8  1345400537626402816        BurauFred                        Alabama   \n",
       "9  1345400537584431104  TheBenduPodcast                     Austin, TX   \n",
       "\n",
       "                       created_at  \\\n",
       "0  Sat Jan 02 16:04:19 +0000 2021   \n",
       "1  Sat Jan 02 16:04:19 +0000 2021   \n",
       "2  Sat Jan 02 16:04:19 +0000 2021   \n",
       "3  Sat Jan 02 16:04:19 +0000 2021   \n",
       "4  Sat Jan 02 16:04:19 +0000 2021   \n",
       "5  Sat Jan 02 16:04:19 +0000 2021   \n",
       "6  Sat Jan 02 16:04:19 +0000 2021   \n",
       "7  Sat Jan 02 16:04:19 +0000 2021   \n",
       "8  Sat Jan 02 16:04:19 +0000 2021   \n",
       "9  Sat Jan 02 16:04:19 +0000 2021   \n",
       "\n",
       "                                                text  \n",
       "0       ask yoni\\n\\nIdk what that means, but okay XD  \n",
       "1  Finally! The word is out. So much has been hap...  \n",
       "2  RT @Raze0013: ‚òÄÔ∏èüê∂#MusicBNK48 ‚ú®‚ú®\\nHappy New Yea...  \n",
       "3  RT @Lindatiny21: ATINY'S  VOTE FOR TODAY! Give...  \n",
       "4  RT @BoycottUtah: Fellow citizens of Georgia. Y...  \n",
       "5  @qorquiq @nicholestrano Jacket over game pajam...  \n",
       "6  RT @asdfghjunyeol: It's 2021, but my heart sti...  \n",
       "7  RT @FaheemYounus: Should I continue my Twitter...  \n",
       "8  RT @RudyGiuliani: Sunday January 3, 2021, Dr. ...  \n",
       "9  RT @sw_holocron: REVIEW: Star Wars The High Re...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the max number of tweets that will be returned\n",
    "max_results = 10\n",
    "\n",
    "# the hashtag or phrase to fetch the tweets for\n",
    "searchtag = \"2021\"\n",
    "\n",
    "# define the query data\n",
    "query_data = {\n",
    "    \"track\": f\"{searchtag}\".replace(\" \", \"\").lower(),\n",
    "    \"language\": \"en\", # the language to use\n",
    "    \"date_since\": \"2019-12-01\" # retrieve only tweets after this date\n",
    "}\n",
    "\n",
    "# the twitter API url (version 1.1)\n",
    "url = \"https://stream.twitter.com/1.1/statuses/filter.json\"\n",
    "\n",
    "# adds the query data to the url\n",
    "query_url = f\"{url}?{'&'.join([f'{k}={v}' for k, v in query_data.items()])}\"\n",
    "print(query_url)\n",
    "\n",
    "data = []\n",
    "print(f\"Retrieving max {max_results} Tweets:\")\n",
    "with twitter.get(query_url, stream=True) as response:\n",
    "    for i, raw_tweet in enumerate(response.iter_lines()):\n",
    "        if i == max_results:\n",
    "            break\n",
    "        if raw_tweet != \"b''\":     \n",
    "            try:\n",
    "                tweet = json.loads(raw_tweet)\n",
    "                userid = tweet['id']\n",
    "                user = tweet['user']\n",
    "                username = user['screen_name']\n",
    "                userlocation = user['location']\n",
    "                created_at = tweet['created_at']\n",
    "                text = tweet['text']\n",
    "                data.append([userid, username, userlocation, created_at, text])\n",
    "                #print(f\"{i+1}/{max_results}: {user}\\n @ {created_at }\\n: {text}\\n\")\n",
    "\n",
    "            except (json.JSONDecodeError, KeyError) as err:\n",
    "                # In case the JSON fails to decode, we skip this tweet\n",
    "                print(f\"{i+1}/{max_results}: ERROR: encountered a problem with a line of data... \\n\")\n",
    "                continue\n",
    "\n",
    "            # write the json file to disk\n",
    "            with pathlib.Path(out_path) / f\"{dt.now().timestamp()}_{uuid4()}.json\" as F:\n",
    "                F.write_bytes(raw_tweet)\n",
    "            \n",
    "df = pd.DataFrame (data, columns = ['userid', 'username', 'userlocation', 'created_at','text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Retrieving Tweets from a specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=barackobama&date_since=2019-12-01\n",
      "Retrieving max 10 Tweets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Fri Jan 01 18:25:46 +0000 2021</td>\n",
       "      <td>2244</td>\n",
       "      <td>21721</td>\n",
       "      <td>And here‚Äôs a story that reminds us of the powe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Fri Jan 01 18:25:45 +0000 2021</td>\n",
       "      <td>26121</td>\n",
       "      <td>290527</td>\n",
       "      <td>After a year that has tested us in unimaginabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Tue Dec 29 19:11:57 +0000 2020</td>\n",
       "      <td>8443</td>\n",
       "      <td>43484</td>\n",
       "      <td>We‚Äôre just one week away from the U.S. Senate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Tue Dec 29 17:10:10 +0000 2020</td>\n",
       "      <td>2217</td>\n",
       "      <td>11630</td>\n",
       "      <td>The redistricting process in 2021 will be a sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Fri Dec 25 00:01:40 +0000 2020</td>\n",
       "      <td>11809</td>\n",
       "      <td>171442</td>\n",
       "      <td>This Christmas looks different for all of us. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Tue Dec 22 18:32:11 +0000 2020</td>\n",
       "      <td>4872</td>\n",
       "      <td>30478</td>\n",
       "      <td>It‚Äôs unconscionable that there are families wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Mon Dec 21 22:30:31 +0000 2020</td>\n",
       "      <td>23703</td>\n",
       "      <td>230213</td>\n",
       "      <td>With COVID cases surging worse than ever, gett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Sat Dec 19 20:01:04 +0000 2020</td>\n",
       "      <td>33242</td>\n",
       "      <td>286359</td>\n",
       "      <td>Here are some of my favorite songs of the year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Fri Dec 18 14:01:54 +0000 2020</td>\n",
       "      <td>10629</td>\n",
       "      <td>127740</td>\n",
       "      <td>Like everyone else, we were stuck inside a lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Thu Dec 17 23:01:50 +0000 2020</td>\n",
       "      <td>2220</td>\n",
       "      <td>17275</td>\n",
       "      <td>From Willie Mays to Mamie Johnson, the players...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Thu Dec 17 18:00:53 +0000 2020</td>\n",
       "      <td>10684</td>\n",
       "      <td>99119</td>\n",
       "      <td>As 2020 comes to a close, I wanted to share my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Wed Dec 16 17:46:24 +0000 2020</td>\n",
       "      <td>2676</td>\n",
       "      <td>27342</td>\n",
       "      <td>I had some fun answering questions about #APro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Mon Dec 14 22:31:57 +0000 2020</td>\n",
       "      <td>3945</td>\n",
       "      <td>29995</td>\n",
       "      <td>There‚Äôs just one day left to sign up for heath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Mon Dec 14 21:11:03 +0000 2020</td>\n",
       "      <td>4389</td>\n",
       "      <td>24647</td>\n",
       "      <td>Georgians, today is the first day of early vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Sun Dec 13 20:07:24 +0000 2020</td>\n",
       "      <td>6296</td>\n",
       "      <td>31836</td>\n",
       "      <td>Georgia‚Äôs runoff election will determine wheth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Fri Dec 11 21:30:03 +0000 2020</td>\n",
       "      <td>3205</td>\n",
       "      <td>17958</td>\n",
       "      <td>Here‚Äôs a great way to call voters in Georgia a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Thu Dec 10 21:01:38 +0000 2020</td>\n",
       "      <td>9387</td>\n",
       "      <td>140161</td>\n",
       "      <td>Happy Hanukkah to all those celebrating around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Wed Dec 09 14:30:33 +0000 2020</td>\n",
       "      <td>2895</td>\n",
       "      <td>29307</td>\n",
       "      <td>In A Promised Land, I talk about the decisions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Tue Dec 08 18:00:28 +0000 2020</td>\n",
       "      <td>3162</td>\n",
       "      <td>25104</td>\n",
       "      <td>With COVID-19 cases reaching an all-time high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Mon Dec 07 14:30:46 +0000 2020</td>\n",
       "      <td>8621</td>\n",
       "      <td>32283</td>\n",
       "      <td>To all of you in Georgia, today is the last da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     screen_name                      created_at  retweet_count  \\\n",
       "0   Barack Obama  Fri Jan 01 18:25:46 +0000 2021           2244   \n",
       "1   Barack Obama  Fri Jan 01 18:25:45 +0000 2021          26121   \n",
       "2   Barack Obama  Tue Dec 29 19:11:57 +0000 2020           8443   \n",
       "3   Barack Obama  Tue Dec 29 17:10:10 +0000 2020           2217   \n",
       "4   Barack Obama  Fri Dec 25 00:01:40 +0000 2020          11809   \n",
       "5   Barack Obama  Tue Dec 22 18:32:11 +0000 2020           4872   \n",
       "6   Barack Obama  Mon Dec 21 22:30:31 +0000 2020          23703   \n",
       "7   Barack Obama  Sat Dec 19 20:01:04 +0000 2020          33242   \n",
       "8   Barack Obama  Fri Dec 18 14:01:54 +0000 2020          10629   \n",
       "9   Barack Obama  Thu Dec 17 23:01:50 +0000 2020           2220   \n",
       "10  Barack Obama  Thu Dec 17 18:00:53 +0000 2020          10684   \n",
       "11  Barack Obama  Wed Dec 16 17:46:24 +0000 2020           2676   \n",
       "12  Barack Obama  Mon Dec 14 22:31:57 +0000 2020           3945   \n",
       "13  Barack Obama  Mon Dec 14 21:11:03 +0000 2020           4389   \n",
       "14  Barack Obama  Sun Dec 13 20:07:24 +0000 2020           6296   \n",
       "15  Barack Obama  Fri Dec 11 21:30:03 +0000 2020           3205   \n",
       "16  Barack Obama  Thu Dec 10 21:01:38 +0000 2020           9387   \n",
       "17  Barack Obama  Wed Dec 09 14:30:33 +0000 2020           2895   \n",
       "18  Barack Obama  Tue Dec 08 18:00:28 +0000 2020           3162   \n",
       "19  Barack Obama  Mon Dec 07 14:30:46 +0000 2020           8621   \n",
       "\n",
       "    favorite_count                                               text  \n",
       "0            21721  And here‚Äôs a story that reminds us of the powe...  \n",
       "1           290527  After a year that has tested us in unimaginabl...  \n",
       "2            43484  We‚Äôre just one week away from the U.S. Senate ...  \n",
       "3            11630  The redistricting process in 2021 will be a sn...  \n",
       "4           171442  This Christmas looks different for all of us. ...  \n",
       "5            30478  It‚Äôs unconscionable that there are families wo...  \n",
       "6           230213  With COVID cases surging worse than ever, gett...  \n",
       "7           286359  Here are some of my favorite songs of the year...  \n",
       "8           127740  Like everyone else, we were stuck inside a lot...  \n",
       "9            17275  From Willie Mays to Mamie Johnson, the players...  \n",
       "10           99119  As 2020 comes to a close, I wanted to share my...  \n",
       "11           27342  I had some fun answering questions about #APro...  \n",
       "12           29995  There‚Äôs just one day left to sign up for heath...  \n",
       "13           24647  Georgians, today is the first day of early vot...  \n",
       "14           31836  Georgia‚Äôs runoff election will determine wheth...  \n",
       "15           17958  Here‚Äôs a great way to call voters in Georgia a...  \n",
       "16          140161  Happy Hanukkah to all those celebrating around...  \n",
       "17           29307  In A Promised Land, I talk about the decisions...  \n",
       "18           25104  With COVID-19 cases reaching an all-time high ...  \n",
       "19           32283  To all of you in Georgia, today is the last da...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the max number of tweets that will be returned\n",
    "max_results = 10\n",
    "\n",
    "# define the query data\n",
    "screen_name = \"Barack Obama\"\n",
    "\n",
    "query_data = {\n",
    "    \"screen_name\": f\"{screen_name}\".replace(\" \", \"\").lower(),\n",
    "    \"date_since\": \"2019-12-01\" # retrieve only tweets after this date\n",
    "}\n",
    "\n",
    "# the twitter API url (version 1.1)\n",
    "url = \"https://api.twitter.com/1.1/statuses/user_timeline.json\"\n",
    "\n",
    "# adds the query data to the url\n",
    "query_url = f\"{url}?{'&'.join([f'{k}={v}' for k, v in query_data.items()])}\"\n",
    "print(query_url)\n",
    "\n",
    "data = []\n",
    "print(f\"Retrieving max {max_results} Tweets:\")\n",
    "with twitter.get(query_url, stream=True) as response:\n",
    "    for i, raw_tweet in enumerate(response.iter_lines()):\n",
    "        if i == max_results:\n",
    "            break\n",
    "        if raw_tweet != \"b''\":     \n",
    "            try:\n",
    "                tweets = json.loads(raw_tweet)\n",
    "                for tweet in tweets: \n",
    "                    #print(str(tweet))\n",
    "                    created_at = tweet['created_at']\n",
    "                    text = tweet['text']\n",
    "                    retweet_count = tweet['retweet_count']\n",
    "                    favorite_count = tweet['favorite_count']\n",
    "                    user = tweet['user']\n",
    "                    username = user['screen_name']\n",
    "                    data.append([screen_name, created_at, retweet_count, favorite_count, text])\n",
    "\n",
    "            except (json.JSONDecodeError, KeyError) as err:\n",
    "                # In case the JSON fails to decode, we skip this tweet\n",
    "                print(f\"{i+1}/{max_results}: ERROR: encountered a problem with a line of data... \\n\")\n",
    "                continue\n",
    "\n",
    "            # write the json file to disk\n",
    "            with pathlib.Path(out_path) / f\"{dt.now().timestamp()}_{uuid4()}.json\" as F:\n",
    "                F.write_bytes(raw_tweet)\n",
    "                \n",
    "df = pd.DataFrame (data, columns = ['screen_name', 'created_at', 'retweet_count', 'favorite_count', 'text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Retrieving Images from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stream.twitter.com/1.1/statuses/filter.json?track=chart&language=en&has=media\n",
      "The current working directory is C:\\Users\\Flo\\relataly-public-python-tutorials\n",
      "Successfully created the directory C:\\Users\\Flo\\relataly-public-python-tutorials/twitter/downloaded_media/02012021-170503-chart \n",
      "Retrieving a total max of 20 Tweets:\n",
      "1/20: ERROR: encountered a problem with a line of data... \n",
      "2/20: ERROR: encountered a problem with a line of data... \n",
      "3/20: ERROR: encountered a problem with a line of data... \n",
      "4/20: ERROR: encountered a problem with a line of data... \n",
      "5/20: ERROR: encountered a problem with a line of data... \n",
      "6/20: ERROR: encountered a problem with a line of data... \n",
      "7/20: ERROR: encountered a problem with a line of data... \n",
      "8/20: ERROR: encountered a problem with a line of data... \n",
      "9/20: ERROR: encountered a problem with a line of data... \n",
      "10/20: ERROR: encountered a problem with a line of data... \n",
      "11/20: ERROR: encountered a problem with a line of data... \n",
      "12/20: ERROR: encountered a problem with a line of data... \n",
      "13/20: ERROR: encountered a problem with a line of data... \n",
      "14/20: ERROR: encountered a problem with a line of data... \n",
      "15/20: ERROR: encountered a problem with a line of data... \n",
      "16/20: ERROR: encountered a problem with a line of data... \n",
      "17/20: ERROR: encountered a problem with a line of data... \n",
      "18/20: ERROR: encountered a problem with a line of data... \n",
      "19/20: ERROR: encountered a problem with a line of data... \n",
      "20/20: ERROR: encountered a problem with a line of data... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>media_id</th>\n",
       "      <th>media_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [created_at, tweet_id, media_id, media_url]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the max number of tweets that will be returned\n",
    "max_results = 20\n",
    "\n",
    "# the hashtag or phrase to fetch the tweets for\n",
    "searchtag = \"chart\"\n",
    "\n",
    "# define the query data\n",
    "query_data = {\n",
    "    \"track\": f\"{searchtag}\".replace(\" \", \"\").lower(),\n",
    "    \"language\": \"en\", # the language to use\" \n",
    "    \"has\": \"media\"\n",
    "}\n",
    "# the twitter API url (version 1.1)\n",
    "url = \"https://stream.twitter.com/1.1/statuses/filter.json\"\n",
    "\n",
    "# adds the query data to the url\n",
    "query_url = f\"{url}?{'&'.join([f'{k}={v}' for k, v in query_data.items()])}\"\n",
    "print(query_url)\n",
    "\n",
    "def defineFolderName(searchtag):\n",
    "    # ddmmYY-HMS\n",
    "    now = dt.now()\n",
    "    dt_string = now.strftime(\"%d%m%Y-%H%M%S\")\n",
    "    \n",
    "    if len(searchtag) > 20:\n",
    "        return dt_string\n",
    "    else:\n",
    "        return dt_string + \"-\" + searchtag\n",
    "\n",
    "def createDir(savepath):\n",
    "    try:\n",
    "        os.makedirs(savepath)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % savepath)\n",
    "        if path.exists(savepath):\n",
    "            print(\"path exists\")\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % savepath)\n",
    "\n",
    "def save_images(savepath, tweet, i):\n",
    "    z = 1\n",
    "    #print(tweet)\n",
    "    entities = tweet['entities']\n",
    "    tweet_url = tweet['id']\n",
    "    created_at = tweet['created_at']\n",
    "    tweet_media = entities['media']\n",
    "    for media in tweet_media: # a tweet can have multiple images/videos\n",
    "        media_url = str(media['media_url_https'])\n",
    "        file_name = media['id']\n",
    "        try:\n",
    "            pic = urllib.request.urlopen(media_url)\n",
    "            file_path = savepath + \"/\" + searchtag + str(i) + \"-\" + str(z) + \".jpg\"\n",
    "            with open(file_path, 'wb') as localFile:\n",
    "                localFile.write(pic.read())\n",
    "            z += 1\n",
    "            #save image origin info\n",
    "            data.append([tweet_url, created_at, file_name, media_url])\n",
    "        except Exception as e:\n",
    "            print('exception at counter ' + str(counter))\n",
    "    \n",
    "# detect the current working directory and print it\n",
    "base_path = os.getcwd()\n",
    "print (\"The current working directory is %s\" % base_path)\n",
    "img_dir = '/twitter/downloaded_media/'\n",
    "data = []\n",
    "\n",
    "# the write path in which the data will be stored. If it does not yet exist, it will be created\n",
    "file_path = base_path + img_dir\n",
    "\n",
    "#createDir(file_path)\n",
    "unique_folder_path = file_path + defineFolderName(searchtag)\n",
    "createDir(unique_folder_path) \n",
    "\n",
    "print(f\"Retrieving a total max of {max_results} Tweets:\")\n",
    "with twitter.get(query_url, stream=True) as response:\n",
    "    for i, raw_tweet in enumerate(response.iter_lines()):\n",
    "        if i == max_results:\n",
    "            break\n",
    "        try:\n",
    "            tweet = json.loads(raw_tweet)\n",
    "            save_images(unique_folder_path, tweet, i)\n",
    "            \n",
    "        except (json.JSONDecodeError, KeyError) as err:\n",
    "            # In case the JSON fails to decode, we skip this tweet\n",
    "            print(f\"{i+1}/{max_results}: ERROR: encountered a problem with a line of data... \")\n",
    "            continue\n",
    "\n",
    "image_df = pd.DataFrame (data, columns = ['created_at', 'tweet_id', 'media_id', 'media_url'])\n",
    "image_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
