{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Retrieving Tweets by Searchtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "# imports the twitter_secrets python file in which we store the twitter API keys\n",
    "from twitter_secrets import twitter_secrets as ts\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "        \n",
    "def set_rules(headers, delete, bearer_token, rules):\n",
    "    payload = {\"add\": rules}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        headers=headers,\n",
    "        json=payload,\n",
    "    )\n",
    "    if response.status_code != 201:\n",
    "        raise Exception(\n",
    "            \"Cannot add rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "def get_rules(headers, bearer_token):\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\", headers=headers\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "    return response.json()\n",
    "\n",
    "def delete_all_rules(headers, bearer_token, rules):\n",
    "    if rules is None or \"data\" not in rules:\n",
    "        return None\n",
    "\n",
    "    ids = list(map(lambda rule: rule[\"id\"], rules[\"data\"]))\n",
    "    payload = {\"delete\": {\"ids\": ids}}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot delete rules (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "\n",
    "def get_stream(headers, set, bearer_token, expansions, fields, save_to_disk, save_path):\n",
    "    data = []\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream\" + expansions + fields, headers=headers, stream=True,\n",
    "    )\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get stream (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    i = 0\n",
    "    for response_line in response.iter_lines():\n",
    "        i += 1\n",
    "        if i == max_results:\n",
    "            break\n",
    "        else:\n",
    "            json_response = json.loads(response_line)\n",
    "            #print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "            try:\n",
    "                save_tweets(json_response)\n",
    "                if save_to_disk == True:\n",
    "                    save_media_to_disk(json_response, save_path)\n",
    "            except (json.JSONDecodeError, KeyError) as err:\n",
    "                # In case the JSON fails to decode, we skip this tweet\n",
    "                print(f\"{i}/{max_results}: ERROR: encountered a problem with a line of data... \\n\")\n",
    "                continue\n",
    "                \n",
    "def save_tweets(tweet):\n",
    "    print(json.dumps(tweet, indent=4, sort_keys=True))\n",
    "    data = tweet['data']\n",
    "    public_metrics = data['public_metrics']\n",
    "    tweet_list.append([data['id'], data['author_id'], data['created_at'], data['text'], public_metrics['like_count']])\n",
    "\n",
    "# the max number of tweets that will be returned\n",
    "max_results = 20\n",
    "\n",
    "# save to disk\n",
    "save_media_to_disk = False\n",
    "save_path = \"\"\n",
    "\n",
    "# You can adjust the rules if needed\n",
    "search_rules = [\n",
    "    {\"value\": \"dog has:images\", \"tag\": \"dog pictures\", \"lang\": \"en\"},\n",
    "    {\"value\": \"cat has:images -grumpy\", \"tag\": \"cat pictures\", \"lang\": \"en\"},\n",
    "]\n",
    "tweet_fields = \"?tweet.fields=attachments,author_id,created_at,public_metrics\"\n",
    "expansions = \"\"\n",
    "tweet_list = []\n",
    "\n",
    "\n",
    "bearer_token = ts.BEARER_TOKEN\n",
    "headers = create_headers(bearer_token)\n",
    "rules = get_rules(headers, bearer_token)\n",
    "delete = delete_all_rules(headers, bearer_token, rules)\n",
    "set = set_rules(headers, delete, bearer_token, search_rules)\n",
    "get_stream(headers, set, bearer_token, expansions, tweet_fields, save_media_to_disk, save_path)\n",
    "\n",
    "df = pd.DataFrame (tweet_list, columns = ['tweetid', 'author_id' , 'created_at', 'text', 'like_count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Retrieving Images And Saving them to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is C:\\Users\\Flo\\relataly-public-python-tutorials\n",
      "Successfully created the directory C:\\Users\\Flo\\relataly-public-python-tutorials/twitter/downloaded_media/02012021-162556 \n",
      "{\"data\": [{\"id\": \"1345390417941032962\", \"value\": \"dog has:images\", \"tag\": \"dog pictures\"}], \"meta\": {\"sent\": \"2021-01-02T15:25:57.044Z\"}}\n",
      "{\"meta\": {\"sent\": \"2021-01-02T15:25:58.424Z\", \"summary\": {\"deleted\": 1, \"not_deleted\": 0}}}\n",
      "{\"data\": [{\"value\": \"dog has:images\", \"tag\": \"dog pictures\", \"id\": \"1345390888374173697\"}], \"meta\": {\"sent\": \"2021-01-02T15:25:59.895Z\", \"summary\": {\"created\": 1, \"not_created\": 0, \"valid\": 1, \"invalid\": 0}}}\n",
      "200\n",
      "{\n",
      "    \"data\": {\n",
      "        \"attachments\": {\n",
      "            \"media_keys\": [\n",
      "                \"3_1345386838672998400\"\n",
      "            ]\n",
      "        },\n",
      "        \"id\": \"1345390856069636096\",\n",
      "        \"text\": \"RT @RussInCheshire: It snowed on my dog https://t.co/8mOyse5EPa\"\n",
      "    },\n",
      "    \"includes\": {\n",
      "        \"media\": [\n",
      "            {\n",
      "                \"height\": 2048,\n",
      "                \"media_key\": \"3_1345386838672998400\",\n",
      "                \"type\": \"photo\",\n",
      "                \"url\": \"https://pbs.twimg.com/media/EqvGM5yXAAA0ZK7.jpg\",\n",
      "                \"width\": 1152\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"matching_rules\": [\n",
      "        {\n",
      "            \"id\": 1345390888374173697,\n",
      "            \"tag\": \"dog pictures\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "exception when saving media url https://pbs.twimg.com/media/EqvGM5yXAAA0ZK7.jpg to path: C:\\Users\\Flo\\relataly-public-python-tutorials/twitter/downloaded_media/02012021-162556/3_1345386838672998400.jpg\n",
      "path exists\n",
      "{\n",
      "    \"data\": {\n",
      "        \"id\": \"1345390856602341377\",\n",
      "        \"text\": \"RT @noshusatti: another murdr,terism of ISB police kills anothr citzn politcns,armd forcs fmiles, lawyr's and all richest person's treat  l\\u2026\"\n",
      "    },\n",
      "    \"matching_rules\": [\n",
      "        {\n",
      "            \"id\": 1345390888374173697,\n",
      "            \"tag\": \"dog pictures\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "2/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "{\n",
      "    \"data\": {\n",
      "        \"id\": \"1345390859894706176\",\n",
      "        \"text\": \"RT @AmitShah: Released the inaugural issue of \\u2018National Police K-9 Journal\\u2019. This is a unique initiative which will further enrich the subj\\u2026\"\n",
      "    },\n",
      "    \"matching_rules\": [\n",
      "        {\n",
      "            \"id\": 1345390888374173697,\n",
      "            \"tag\": \"dog pictures\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "3/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "{\n",
      "    \"data\": {\n",
      "        \"id\": \"1345390862453276675\",\n",
      "        \"text\": \"RT @AmitShah: Released the inaugural issue of \\u2018National Police K-9 Journal\\u2019. This is a unique initiative which will further enrich the subj\\u2026\"\n",
      "    },\n",
      "    \"matching_rules\": [\n",
      "        {\n",
      "            \"id\": 1345390888374173697,\n",
      "            \"tag\": \"dog pictures\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "4/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "{\n",
      "    \"data\": {\n",
      "        \"attachments\": {\n",
      "            \"media_keys\": [\n",
      "                \"3_1345390862411333632\"\n",
      "            ]\n",
      "        },\n",
      "        \"id\": \"1345390863317258242\",\n",
      "        \"text\": \"\\u0915\\u093f\\u0938\\u093e\\u0928 \\u0928\\u0947 \\u092c\\u091a\\u094d\\u091a\\u094b\\u0902 \\u0915\\u0947 \\u0928\\u0939\\u0940\\u0902 \\u092a\\u093e\\u0932\\u0924\\u0942 \\u0915\\u0941\\u0924\\u094d\\u0924\\u0947 \\u0915\\u0947 \\u0928\\u093e\\u092e \\u0915\\u0930 \\u0926\\u0940 \\u0938\\u093e\\u0930\\u0940 \\u091c\\u093e\\u092f\\u0926\\u093e\\u0926, \\u0935\\u091c\\u0939 \\u091c\\u093e\\u0928 \\u0906\\u092a \\u092d\\u0940 \\u0915\\u0939\\u0947\\u0902\\u0917\\u0947 ''\\u0935\\u093e\\u0939''\\nhttps://t.co/tvv00EQNZg\\n\\n#MadhyaPradesh #Chhindwara #OmNarayanVerma #Property #Farmer #LifestyleNews https://t.co/tCjY52T022\"\n",
      "    },\n",
      "    \"includes\": {\n",
      "        \"media\": [\n",
      "            {\n",
      "                \"height\": 420,\n",
      "                \"media_key\": \"3_1345390862411333632\",\n",
      "                \"type\": \"photo\",\n",
      "                \"url\": \"https://pbs.twimg.com/media/EqvJ3HYVgAARoZ_.jpg\",\n",
      "                \"width\": 640\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"matching_rules\": [\n",
      "        {\n",
      "            \"id\": 1345390888374173697,\n",
      "            \"tag\": \"dog pictures\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "exception when saving media url https://pbs.twimg.com/media/EqvJ3HYVgAARoZ_.jpg to path: C:\\Users\\Flo\\relataly-public-python-tutorials/twitter/downloaded_media/02012021-162556/3_1345390862411333632.jpg\n",
      "path exists\n",
      "{\n",
      "    \"data\": {\n",
      "        \"id\": \"1345390864202346503\",\n",
      "        \"text\": \"RT @TruthBCrocheted: \\ud83d\\udc3eDOG BANDANAS \\ud83d\\udc3e\\n\\n\\ud83c\\udf08 other colors available \\ud83c\\udf08 \\njust mssge me on Etsy/Twitter/Instagram \\n\\nhttps://t.co/rFyvvOKPCb https:/\\u2026\"\n",
      "    },\n",
      "    \"matching_rules\": [\n",
      "        {\n",
      "            \"id\": 1345390888374173697,\n",
      "            \"tag\": \"dog pictures\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "6/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "{\n",
      "    \"data\": {\n",
      "        \"id\": \"1345390864051257356\",\n",
      "        \"text\": \"RT @factsonfiIm: In 'Up' (2009), Dug is the only dog to successfully track down the tropical bird because he is the only hunting dog (Golde\\u2026\"\n",
      "    },\n",
      "    \"matching_rules\": [\n",
      "        {\n",
      "            \"id\": 1345390888374173697,\n",
      "            \"tag\": \"dog pictures\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "7/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "{\n",
      "    \"data\": {\n",
      "        \"id\": \"1345390866563813376\",\n",
      "        \"text\": \"RT @MeerSJatoi1: another murdr,terism of ISB police kills anothr citzn politcns,armd forcs fmiles, lawyr's and all richest person's treat\\u2026\"\n",
      "    },\n",
      "    \"matching_rules\": [\n",
      "        {\n",
      "            \"id\": 1345390888374173697,\n",
      "            \"tag\": \"dog pictures\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "8/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "{\n",
      "    \"data\": {\n",
      "        \"attachments\": {\n",
      "            \"media_keys\": [\n",
      "                \"3_1345229191298609153\"\n",
      "            ]\n",
      "        },\n",
      "        \"id\": \"1345390866748366849\",\n",
      "        \"text\": \"RT @animalaleatory: \\\"Pode entrar, ele s\\u00f3 vai te cheirar\\\"\\n\\no dog: https://t.co/fW5dsK8du3\"\n",
      "    },\n",
      "    \"includes\": {\n",
      "        \"media\": [\n",
      "            {\n",
      "                \"height\": 1234,\n",
      "                \"media_key\": \"3_1345229191298609153\",\n",
      "                \"type\": \"photo\",\n",
      "                \"url\": \"https://pbs.twimg.com/media/Eqs20njW8AErSj5.jpg\",\n",
      "                \"width\": 1080\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"matching_rules\": [\n",
      "        {\n",
      "            \"id\": 1345390888374173697,\n",
      "            \"tag\": \"dog pictures\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "exception when saving media url https://pbs.twimg.com/media/Eqs20njW8AErSj5.jpg to path: C:\\Users\\Flo\\relataly-public-python-tutorials/twitter/downloaded_media/02012021-162556/3_1345229191298609153.jpg\n",
      "path exists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>preview_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1345390856069636096</td>\n",
       "      <td>https://pbs.twimg.com/media/EqvGM5yXAAA0ZK7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1345390863317258242</td>\n",
       "      <td>https://pbs.twimg.com/media/EqvJ3HYVgAARoZ_.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1345390866748366849</td>\n",
       "      <td>https://pbs.twimg.com/media/Eqs20njW8AErSj5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid                                preview_image_url\n",
       "0  1345390856069636096  https://pbs.twimg.com/media/EqvGM5yXAAA0ZK7.jpg\n",
       "1  1345390863317258242  https://pbs.twimg.com/media/EqvJ3HYVgAARoZ_.jpg\n",
       "2  1345390866748366849  https://pbs.twimg.com/media/Eqs20njW8AErSj5.jpg"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import json \n",
    "import pandas as pd\n",
    "import urllib\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# imports the twitter_secrets python file in which we store the twitter API keys\n",
    "from twitter_secrets import twitter_secrets as ts\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "        \n",
    "def set_rules(headers, delete, bearer_token, rules):\n",
    "    payload = {\"add\": rules}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        headers=headers,\n",
    "        json=payload,\n",
    "    )\n",
    "    if response.status_code != 201:\n",
    "        raise Exception(\n",
    "            \"Cannot add rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "def get_rules(headers, bearer_token):\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\", headers=headers\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "    return response.json()\n",
    "\n",
    "def delete_all_rules(headers, bearer_token, rules):\n",
    "    if rules is None or \"data\" not in rules:\n",
    "        return None\n",
    "\n",
    "    ids = list(map(lambda rule: rule[\"id\"], rules[\"data\"]))\n",
    "    payload = {\"delete\": {\"ids\": ids}}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot delete rules (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "\n",
    "def get_stream(headers, set, bearer_token, expansions, fields, save_to_disk, save_path):\n",
    "    data = []\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream\" + expansions + fields, headers=headers, stream=True,\n",
    "    )\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get stream (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    i = 0\n",
    "    for response_line in response.iter_lines():\n",
    "        i += 1\n",
    "        if i == max_results:\n",
    "            break\n",
    "        else:\n",
    "            json_response = json.loads(response_line)\n",
    "            #print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "            try:\n",
    "                save_tweets(json_response)\n",
    "                if save_to_disk == True:\n",
    "                    save_media_to_disk(json_response, save_path)\n",
    "            except (json.JSONDecodeError, KeyError) as err:\n",
    "                # In case the JSON fails to decode, we skip this tweet\n",
    "                print(f\"{i}/{max_results}: ERROR: encountered a problem with a line of data... \\n\")\n",
    "                continue\n",
    "                \n",
    "def save_tweets(tweet):\n",
    "    print(json.dumps(tweet, indent=4, sort_keys=True))\n",
    "    data = tweet['data']\n",
    "    #print(json.dumps(data, indent=4, sort_keys=True))\n",
    "    includes = tweet['includes']\n",
    "    media = includes['media']\n",
    "    for line in media:\n",
    "        tweet_list.append([data['id'], line['url']])  \n",
    "        \n",
    "def save_media_to_disk(tweet, save_path):\n",
    "    data = tweet['data']\n",
    "    #print(json.dumps(data, indent=4, sort_keys=True))\n",
    "    includes = tweet['includes']\n",
    "    media = includes['media']\n",
    "    for line in media:\n",
    "        media_url = line['url']\n",
    "        media_key = line['media_key']\n",
    "        pic = urllib.request.urlopen(media_url)\n",
    "        file_path = save_path + \"/\" + media_key + \".jpg\"\n",
    "        try:\n",
    "            with open(file_path, 'wb') as localFile:\n",
    "                localFile.write(pic.read())\n",
    "            tweet_list.append(media_key, media_url)\n",
    "        except Exception as e:\n",
    "            print('exception when saving media url ' + media_url + ' to path: ' + file_path)\n",
    "            if path.exists(file_path):\n",
    "                print(\"path exists\")\n",
    "    \n",
    "def createDir(save_path):\n",
    "    try:\n",
    "        os.makedirs(save_path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % save_path)\n",
    "        if path.exists(savepath):\n",
    "            print(\"file already exists\")\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % save_path)\n",
    "        \n",
    "# save to disk\n",
    "save_to_disk = True\n",
    " \n",
    "if save_to_disk == True: \n",
    "    # detect the current working directory and print it\n",
    "    base_path = os.getcwd()\n",
    "    print (\"The current working directory is %s\" % base_path)\n",
    "    img_dir = '/twitter/downloaded_media/'\n",
    "    # the write path in which the data will be stored. If it does not yet exist, it will be created\n",
    "    now = dt.now()\n",
    "    dt_string = now.strftime(\"%d%m%Y-%H%M%S\")# ddmmYY-HMS\n",
    "    save_path = base_path + img_dir + dt_string\n",
    "    createDir(save_path)\n",
    "    \n",
    "# the max number of tweets that will be returned\n",
    "max_results = 10\n",
    "\n",
    "# You can adjust the rules if needed\n",
    "search_rules = [\n",
    "    {\"value\": \"dog has:images\", \"tag\": \"dog pictures\", \"lang\": \"en\"},\n",
    "]\n",
    "\n",
    "media_fields = \"&media.fields=duration_ms,height,media_key,preview_image_url,public_metrics,type,url,width\"\n",
    "expansions = \"?expansions=attachments.media_keys\"\n",
    "tweet_list = []\n",
    "\n",
    "bearer_token = ts.BEARER_TOKEN\n",
    "headers = create_headers(bearer_token)\n",
    "rules = get_rules(headers, bearer_token)\n",
    "delete = delete_all_rules(headers, bearer_token, rules)\n",
    "set = set_rules(headers, delete, bearer_token, search_rules)\n",
    "get_stream(headers, set, bearer_token, expansions, media_fields, save_to_disk, save_path)\n",
    "\n",
    "df = pd.DataFrame (tweet_list, columns = ['tweetid', 'preview_image_url'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
